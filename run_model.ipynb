{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "\n",
    "def data_clean(landmark):\n",
    "\n",
    "    data = landmark[0]\n",
    "\n",
    "    try:\n",
    "        data = str(data)\n",
    "\n",
    "        data = data.strip().split('\\n')\n",
    "\n",
    "        garbage = ['landmark {', '  visibility: 0.0', '  presence: 0.0', '}']\n",
    "\n",
    "        without_garbage = []\n",
    "\n",
    "        for i in data:\n",
    "            if i not in garbage:\n",
    "                without_garbage.append(i)\n",
    "\n",
    "        clean = []\n",
    "\n",
    "        for i in without_garbage:\n",
    "            i = i.strip()\n",
    "            clean.append(i[2:])\n",
    "\n",
    "        for i in range(0, len(clean)):\n",
    "            clean[i] = float(clean[i])\n",
    "\n",
    "        return ([clean])\n",
    "\n",
    "    except:\n",
    "        return (np.zeros([1, 63], dtype=int)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the Euclidean distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.linalg.norm(point1 - point2)\n",
    "\n",
    "# Function to check hand stability based on landmark movement\n",
    "\n",
    "\n",
    "def check_hand_stability(landmarks_history):\n",
    "    # Check if the Euclidean distances between consecutive landmark positions are below a threshold\n",
    "    threshold = 10.0\n",
    "    for i in range(len(landmarks_history[0]) - 1):\n",
    "        distance = calculate_distance(\n",
    "            landmarks_history[0][i], landmarks_history[0][i + 1])\n",
    "        if distance > threshold:\n",
    "            return False\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# For webcam input:\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7,\n",
    "                       min_tracking_confidence=0.5)\n",
    "clf = joblib.load('E:\\CourseHKII_Grade3\\seminar\\model_svm.pkl')\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Create a window for displaying the output\n",
    "# cv2.namedWindow(\"Sign Language Recognition\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Initialize variables for storing predicted results\n",
    "previous_prediction = None\n",
    "predicted_string = ''\n",
    "landmarks_history = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.flip(image, 1)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Process the image with MediaPipe Hands\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    # Draw the hand landmarks on the image\n",
    "    if results.multi_hand_landmarks:\n",
    "        for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            if results.multi_handedness:\n",
    "                handedness = results.multi_handedness[idx].classification[0].label\n",
    "                if handedness == 'Right':\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    # Clean hand landmarks data\n",
    "                    cleaned_landmark = data_clean(results.multi_hand_landmarks)\n",
    "\n",
    "                    if cleaned_landmark:\n",
    "                        # Check hand stability based on landmark movement\n",
    "                        landmarks_history.append(cleaned_landmark)\n",
    "                        if len(landmarks_history) > 10:\n",
    "                            landmarks_history.pop(0)\n",
    "                            if check_hand_stability(landmarks_history):\n",
    "                                # Make predictions using the trained model\n",
    "                                y_pred = clf.predict(cleaned_landmark)\n",
    "                                # Update the predicted sequence if a new prediction is made\n",
    "                                if y_pred[0] != previous_prediction:\n",
    "                                    previous_prediction = y_pred[0]\n",
    "                                    if (y_pred[0] == 'del'):\n",
    "                                        predicted_string = ''\n",
    "                                        previous_prediction = None\n",
    "                                    elif (y_pred[0] == 'space'):\n",
    "                                        predicted_string += ' '\n",
    "                                    else:\n",
    "                                        predicted_string += y_pred[0]\n",
    "                        # Get the size of the predicted text\n",
    "                        (text_width, text_height), _ = cv2.getTextSize(\n",
    "                            predicted_string[-10:], cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "\n",
    "                        # Calculate the coordinates for the bounding box\n",
    "                        x1 = 50\n",
    "                        y1 = 50\n",
    "                        x2 = x1 + text_width + 20\n",
    "                        y2 = y1 + text_height + 20\n",
    "\n",
    "                        # Draw the bounding box rectangle\n",
    "                        if (len(predicted_string) > 0):\n",
    "                            cv2.rectangle(image, (x1, y1), (x2, y2),\n",
    "                                          (255, 255, 255), 2)\n",
    "\n",
    "                        # Draw the predicted text\n",
    "                        cv2.putText(\n",
    "                            image, predicted_string[-10:], (x1 + 10,\n",
    "                                                            y1 + text_height + 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0,\n",
    "                                                          0, 255), 2, cv2.LINE_AA\n",
    "                        )\n",
    "                        # # Display the image with hand landmarks and predicted sequence\n",
    "                        # image_with_predictions = cv2.putText(\n",
    "                        #     image.copy(), predicted_string[-10:], (50, 50),\n",
    "                        #     cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA\n",
    "                        # )\n",
    "\n",
    "                        cv2.imshow('Sign Language Recognition', image)\n",
    "                else:\n",
    "                    # If no hand landmarks are detected, display the original image\n",
    "                    cv2.imshow('Sign Language Recognition', image)\n",
    "\n",
    "    else:\n",
    "        # If no hand landmarks are detected, display the original image\n",
    "        cv2.imshow('Sign Language Recognition', image)\n",
    "\n",
    "    # Break the loop when 'Esc' key is pressed\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
